\documentclass{article}
\usepackage[dvips]{graphicx}
\begin{document}

\begin{abstract}
  The report describes two attempts to train
  the artificial neural network (ANN) to distinguish
  10 categories data given in CIFAR-10 benchmark dataset.
  Two approaches: shallow classifier and transfer learning were presented.
  The former was unsuccessful, due to improper choice of fixed
  convolution filters. The latter resulted in 88\% accuracy,
  which is not the state of the art result, but undoubtedly positively
  verifies the transfer learning approach
  
\end{abstract}

\section{Problem overview}

The task was to write a scripts for image recognition, specifically CIFAR-10 dataset.
It contains 60000 color images of size 32 by 32 grouped into 10 categories.
The reference set is divided into 5 training and one test set, each of size 10000
images. The suggested methods for performing the task was transfer learning and
building the shallow classifier.

Before these two methods will be described, a few words should be written about
image recognition, at general. The state of the art method is so-called
convolutional neural network. The canonical neural network formulation assumes
that  the signal is transmitted from input layer, through a number of hidden layers
to the output layer, where each of them can be equivalent $i$ equations of the form
\begin{equation}
  \label{eq}
  out_i = f \left( \sum_{j=1}^{N} a_{i,j} in_j + b_i \right)
\end{equation}
where $in$ are the input signals $out$ are outputs, $b$ is a bias
defined for each output neuron separately and $f$ is (nonlinear)
activation function. Parameters $a_{i,j}$ are supposed to be found during training
(optimization) process.

In case of convolutional neural network, before the data are passed through
layers equivalent to (\ref{eq}), they are convoluted and passed through nonlinear
filters. The coefficients of the filters are also subject to be optimized.
What is worth to note, the number of possible states
within NN layer is larger than number of states in analyzed picture, which
make system of neurons strongly overdetermined.


\section{Preliminary tasks}

Before any image processing can be done, the data must be downloaded and appropriately prepared
for further analysis. Image datasets are relatively big, thus
the data should be downloaded once and kept for further processing. The {\bf cifar\_init.py}
script responsible, for downloading CIFAR-10 dataset checks if the data are present in current directory,
and downloads is if it is necessary. The script calls external commands: {\bf wget} and
{\bf tar} so it must be run in UNIX-like environment (Linux,BSD,Darwin,OS X).

\begin{figure}[!hbt]
  \centering
%  \includegraphics[width=.8\textwidth]{dset.eps}
  \caption{Example figures grouped into 10 categories}
\end{figure}


\section{Shallow Classifier \label{sec}}

The shallow classifier, was build according to \cite{shallow}. The difference
between full CNN and the shallow classifier is the definition of convolutional
filters. In canonical CNN model, the coefficients of the filters are optimized,
in the simplified approach they are fixed. In \cite{shallow}, as
the filters act: vertical and horizontal bars, central parts of classified
figures and the set trained for another model. At general, training networks
for image recognition is very resource consuming task, thus reuse of existent
results is generally a good idea.

In this task, the classifier was build using Haar wavelets and Legendre polynomials
as for convolutional layer. Since the strides for convolution are larger than one,
the side effect of the convolution is decimation, thus no explicit downsampling is
needed. However, the results were disappointing. Although for the
train set the 2 layer hidden network of 128 or 256 neurons feed by
the data filtered by above mentioned filters is was possible to get 90\% match,
the hit rate for the testing set was approximately 10\%, which is
what one could expect randomly labeling the images. 

The results were calculated with scripts {\bf shallow4.py} and {\bf shallow\_leg.py}.
No improvement has been observed when some simple shapes (bar,dot) were used
{\bf shallow\_arb.py}. The conclusion is, that the filters in the shallow
classifier, although set arbitrarily, must reflect some knowledge about
the classified object.




\section{Transfer learning}

The aim of transfer learning is to utilize existing trained network for classification
of another set of data. For this task, the {\em inception-v3} model has been chosen.
The flow of the network os presented in Fig. \ref{incept}. According to the
figure, the data was passed directly to {\em ExpandDims} layer, in order to avoid
jpeg decompression and integer to float conversion, since the CIFAR data are
floating point. The output was taken from {\em pool\_3} layer,
which has the smalles possible size but is placed before the final classification.
The model is trained to distinguish 2048 classes, while only 10 are needed.

\begin{figure}[!hbt]
  \centering
%  \includegraphics[width=.3\textwidth]{inception.eps}
  \caption{\label{incept}Inception-v3 model graph}
\end{figure}

The first part of the toolchain is to process CIFAR data through the
graph. The responsible script is  {\bf inception\_features.py}.
It takes the image data and outputs a large csv file (approx 300M)
per batch. As expected, the response of neurons responsible for activating
several of 2048 was generally much stronger than others.


\begin{figure}[!hbt]
  \centering
%  \includegraphics[width=.3\textwidth]{inception.eps}
  \caption{\label{svd1}Inception-v3 model graph}
\end{figure}

\begin{figure}[!hbt]
  \centering
%  \includegraphics[width=.3\textwidth]{inception.eps}
  \caption{\label{svd2}Inception-v3 model graph}
\end{figure}

In order to, at least partially, visualize so big set, two vectors,
corresponding to the biggest singular values were chosen. As seen
in Figures \ref{svd1} and \ref{svd2}, the colors (corresponding
to different labels) are partially separable. This observation
resulted in an idea to use the singular vectors instead
of direct {\it inception-v3} output. This approach, however
resulted in a very poor result: the hit rate for the test
did not exceed  60\%. On the contrary, when all 2048
features were used for svm classification, the accuracy
was as large as 88\%. The result were calculated using 
{\bf inception\_svm.py} script.

\section{Concluding remarks}

For this task, very helpful were tutorials \cite{tf}, \cite{tfsvm}.
The most creative part was training the shallow classifier,
unfortunately with no great success, however changes suggested
in section \ref{sec}, namely better choice of filters
should result in significant improvement. It would require
spending more time, and some human interaction
in order to get some important and useful heuristics.




%
%Legendre n=8, skip 2, L=128 d=2
%23 0.123136 181 1.37976
%
% Haar 128
% 14 0.0710252 184 1.21792
% Haar 256
%17 0.0850028 168 1.32363

\begin{thebibliography}{1}

\bibitem{tf} Tenorflow Documentation {\em https://www.tensorflow.org/api\_docs/python/tf}
\bibitem{tfsvm} Tensorflow tutorial {\em https://www.kernix.com/blog/image-classification-with-a-pre-trained-deep-neural-network\_p11}
\bibitem{cifar} Alex Krizhevsky: {\em Learning Multiple Layers of Features from Tiny Images}. Tech report 2009.
\bibitem{inception} Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jonathon Shlens, Zbigniew Wojna, {\em Rethinking the Inception Architecture for Computer Vision},  arXiv:1512.00567, Dec 2015.
\bibitem{shallow} Mark D. McDonnell, Tony Vladusich: {\em Enhanced Image Classification With a Fast-Learning Shallow Convolutional Neural Network},  	arXiv:1503.04596, Aug 2015.
  

\end{thebibliography}
\end{document}
